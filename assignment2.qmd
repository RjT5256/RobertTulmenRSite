---
title: "Assignment2"
---

What we're missing - Enterprise data. The thing that will separate all of us using the same model will be the quality and quantity of data we can obtain. The key to enterprise data is decision making; it allows you to affect your future or have some forecast of what is going to happen. We "need to be able to make predictions," according to Jure Leskovec. The AI revolution has taken us by force because of RCNNs. The way we process knowledge has completely diverged from the old ways, but decision making is still archaic. ML and predictive AI have yet to be "touched," and we can still make large advances towards that goal of highly accurate predictive modeling. Any kind of predictive tasks in tandem with loss functions can be tuned to any situation because of the non-factor of needing pre-training. Risk assessment, customer service, healthcare, finance—anything that gets better with predictive analysis—can be heavily influenced by graph-transformed models. There are still some nuances to the science, but the end goal, or "what is promised," is no pre-training requirement and an accurate prediction in under a second. Right now, pre-trained models can be as accurate as senior data scientists, but if you want to push it further you can fine-tune the model by using data specific to your task and it becomes superhuman accurate. This is especially great for fraud protection. Real-world examples would be user ad matching, ad relevance. Reddit, in a matter of a couple of months, built a "three-year" model by virtue of having so much data and a growing community to all pitch into it. The role of a data scientist won't go away but will shift to modeling the data and determining the business impact. It will, however, be much faster and far more accurate, creating a new environment for several different disciplines.
