# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
rlang::last_trace()
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# steamcharts <- read_html(url)
# class(steamcharts)
#
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
#
#
# steam <- steamcharts %>%
#   html_nodes(xpath='//*[@id="top-games"]') %>%
#   html_table()
# class(steam)
# chartInfo = steam[[1]]
#
# head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played")
# Remove "trailing notes in Date variable 'Last 30 days' column
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# steamcharts <- read_html(url)
# class(steamcharts)
#
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
#
#
# steam <- steamcharts %>%
#   html_nodes(xpath='//*[@id="top-games"]') %>%
#   html_table()
# class(steam)
# chartInfo = steam[[1]]
#
# head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played")
# Remove "trailing notes in Date variable 'Last 30 days' column
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
# ðŸ‘‡ CRITICAL FIX: Rename the first column (which is "") to "Rank"
# This must be done before the 'mutate' step.
# We use a base R function since the column name is invalid for tidyverse functions.
colnames(table_df)[1] <- "Rank_Placeholder"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# steamcharts <- read_html(url)
# class(steamcharts)
#
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
#
#
steam <- steamcharts %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
class(steam)
chartInfo = steam[[1]]
head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played")
# Remove "trailing notes in Date variable 'Last 30 days' column
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
write.csv(chartInfo, "chartInfo.csv", row.names = FALSE)
colnames(table_df)[1] <- "Rank"
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
colnames(table_df)[1] <- "Rank"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# steamcharts <- read_html(url)
# class(steamcharts)
#
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
#
#
steam <- steamcharts %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
class(steam)
chartInfo = steam[[1]]
head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played")
# Remove "trailing notes in Date variable 'Last 30 days' column
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
write.csv(chartInfo, "chartInfo.csv", row.names = FALSE)
View(chartInfo)
View(steam)
View(steamcharts)
View(chartInfo)
return(table_df)
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
colnames(table_df)[1] <- "Rank"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# 3. CLEAN UP (Rest of your script)
print(paste("Total rows scraped:", nrow(chartInfo)))
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played", "Page")
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
head(chartInfo)
# steamcharts <- read_html(url)
# class(steamcharts)
#
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
#
#
steam <- steamcharts %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
class(steam)
chartInfo = steam[[1]]
head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played")
# Remove "trailing notes in Date variable 'Last 30 days' column
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
write.csv(chartInfo, "chartInfo.csv", row.names = FALSE)
head(chartInfo)
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
colnames(table_df)[1] <- "Rank"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# 3. CLEAN UP (Rest of your script)
head(chartInfo)
# steamcharts <- read_html(url)
# class(steamcharts)
# steam <- steamcharts %>%
#   html_nodes(xpath='//*[@id="top-games"]') %>%
#   html_table()
# class(steam)
# chartInfo = steam[[1]]
#
# head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
# Remove "trailing notes in Date variable 'Last 30 days' column
print(paste("Total rows scraped:", nrow(chartInfo)))
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played", "Page")
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
# write.csv(chartInfo, "chartInfo.csv", row.names = FALSE)
## Workshop: Scraping webpages with R rvest package
# Prerequisites: Chrome browser, Selector Gadget (https://selectorgadget.com/)
library(tidyverse)
library(rvest)
library(purrr)
# ## Get the XPath data using Inspect element feature in Safari, Chrome or Firefox
# ## At Inspect tab, look for <table class=....> tag. Leave the table close
# ## Right click the table and Copy XPath, paste at html_nodes(xpath =)
PAGES_TO_SCRAPE <- 10
base_url <- 'https://steamcharts.com/top/p.'
#Reading the HTML code from the SteamCharts Website
chartInfo <- 1:PAGES_TO_SCRAPE %>%
map_dfr(~ {
# Be polite: pause for 1 second between requests
Sys.sleep(1)
# a) Construct the specific URL for the current page number (.x)
current_url <- paste0(base_url, .x)
# b) Read the page and scrape the table using your established XPath
page_data <- read_html(current_url) %>%
html_nodes(xpath='//*[@id="top-games"]') %>%
html_table()
# The table data is the first element in the list
table_df <- page_data[[1]]
colnames(table_df)[1] <- "Rank"
# c) Add a column to track the page
table_df <- table_df %>%
mutate(Page = .x)
return(table_df)
})
# 3. CLEAN UP (Rest of your script)
head(chartInfo)
# steamcharts <- read_html(url)
# class(steamcharts)
# steam <- steamcharts %>%
#   html_nodes(xpath='//*[@id="top-games"]') %>%
#   html_table()
# class(steam)
# chartInfo = steam[[1]]
#
# head(chartInfo$Name, n=10)
## Clean up variables
## What type is Rank?
## How about Date? How to fix it?
# Remove "trailing notes in Date variable 'Last 30 days' column
print(paste("Total rows scraped:", nrow(chartInfo)))
colnames(chartInfo) <- c("Rank", "Name", "Current Players", "Last 30 Days", "Peak Players", "Hours Played", "Page")
chartInfo <- chartInfo %>%
select(-"Last 30 Days")
write.csv(chartInfo, "chartInfo.csv", row.names = FALSE)
print(chartInfo)
